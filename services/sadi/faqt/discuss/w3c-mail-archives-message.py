#3> <> prov:specializationOf <#TEMPLATE/path/to/public/source-code.py>;
#3>    rdfs:seeAlso <https://github.com/timrdf/DataFAQs/wiki/FAqT-Service> .

import faqt

import sadi
from rdflib import *
import surf

from surf import *
from surf.query import a, select

import rdflib
rdflib.plugin.register('sparql', rdflib.query.Processor,
                       'rdfextras.sparql.processor', 'Processor')
rdflib.plugin.register('sparql', rdflib.query.Result,
                       'rdfextras.sparql.query', 'SPARQLQueryResult')

import httplib
from urlparse import urlparse, urlunparse
import urllib
import urllib2

import time

from BeautifulSoup import BeautifulSoup

# These are the namespaces we are using beyond those already available
# (see http://packages.python.org/SuRF/modules/namespace.html#registered-general-purpose-namespaces)
ns.register(moat='http://moat-project.org/ns#')
ns.register(ov='http://open.vocab.org/terms/')
ns.register(void='http://rdfs.org/ns/void#')
ns.register(dcat='http://www.w3.org/ns/dcat#')
ns.register(dcterms='http://purl.org/dc/terms/')
ns.register(sd='http://www.w3.org/ns/sparql-service-description#')
ns.register(conversion='http://purl.org/twc/vocab/conversion/')
ns.register(datafaqs='http://purl.org/twc/vocab/datafaqs#')
ns.register(sioc='http://rdfs.org/sioc/ns#')
ns.register(lists='http://lists.w3.org/#')
ns.register(hello='http://sadiframework.org/examples/hello.owl#')

# The Service itself
class W3CMailingListMessage(faqt.Service):

   # Service metadata.
   label                  = 'w3c-mail-archives-message'
   serviceDescriptionText = 'Returns an RDF description of the given W3C Mailing List.'
   comment                = ''
   serviceNameText        = 'w3c-mail-archives-message' # Convention: Match 'name' below.
   name                   = 'w3c-mail-archives-message' # This value determines the service URI relative to http://localhost:9229/
                                                        # Convention: Use the name of this file for this value.
   dev_port = 9231

   def __init__(self):
      # DATAFAQS_PROVENANCE_CODE_RAW_BASE                   +  servicePath  +  '/'  + self.serviceNameText
      # DATAFAQS_PROVENANCE_CODE_PAGE_BASE                  +  servicePath  +  '/'  + self.serviceNameText
      #
      # ^^ The source code location
      #    aligns with the deployment location \/
      #
      #                 DATAFAQS_BASE_URI  +  '/datafaqs/'  +  servicePath  +  '/'  + self.serviceNameText
      faqt.Service.__init__(self, servicePath = 'services/sadi/faqt/discuss')

   def getOrganization(self):
      result                      = self.Organization()
      result.mygrid_authoritative = True
      result.protegedc_creator    = 'lebot@rpi.edu'
      result.save()
      return result

   # This archive was generated by hypermail 2.2.0+W3C-0.50
   def getInputClass(self):
      return ns.SIOC['Item'] # e.g. http://lists.w3.org/Archives/Public/public-prov-wg/2012Mar

   def getOutputClass(self):
      return ns.DATAFAQS['EvaluatedDataset']

   def process(self, input, output):

      print 'sleeping...'
      time.sleep(2)

      print 'processing ' + input.subject
      base = re.sub('/[^/]*$','',input.subject)

      # Query the RDF graph POSTed: input.session.default_store.execute
      # [] a hello:SecondaryParameters; 
      #   hello:author_identification_stance hello:conservative .
      query = select('?stance').where(('?parameters', a, ns.HELLO['SecondaryParameters']),
                                      ('?parameters', ns.HELLO['author_identification_stance'], ns.HELLO['conservative']))
      conservative = True if len(input.session.default_store.execute(query)) else False
      print 'conservative: ' + str(conservative)

      Container = output.session.get_class(ns.SIOC['Container'])
      Item      = output.session.get_class(ns.SIOC['Item'])

      page  = urllib2.urlopen(input.subject)
      soup  = BeautifulSoup(page)

      predicates = {
         'Previous message' : ns.SIOC['previous_by_date'],
         'This message'     : None,                       # We know that we don't want to do anything.
         'Next message'     : ns.SIOC['next_by_date'],
         'In reply to'      : ns.SIOC['reply_of'],
         'Next in thread'   : ns.LISTS['next_in_thread'], # TODO
         'Reply'            : ns.SIOC['has_reply'],
         'Maybe reply'      : ns.LISTS['maybe_reply']     # TODO
      }
      for link in soup.find('map', {'id':'navbarfoot'}).findAll('ul')[0].findAll('li'):
         #print link
         anchor = link.find( href=re.compile(".*") )
         if anchor is not None:
            target = anchor['href'] # can be 0023.html
                                    #     or http://www.w3.org/mid/4E365D3A.8060808@ecs.soton.ac.uk (if first email of month)
            if re.search('.html$',target):
               target = base + '/' + re.sub('.html$','',target)
            elif re.search('.*@.*',target):
               target = target
            else:
               print 'how to handle this? ' + target
               target = None

            if target is not None:
               predicate = ''
               if link.dfn.string in predicates:
                  if predicates[link.dfn.string] is not None:
                     predicate = predicates[link.dfn.string]

               print link.dfn.string + ' (' + predicate + ') ' + target
               print
               targetR = Item(target)
               targetR.save()

               if   link.dfn.string == 'Previous message':
                  output.sioc_previous_by_date.append(targetR)
               elif link.dfn.string == 'This message':
                  cowboy = 5
                  # We know that we don't want to do anything.
               elif link.dfn.string == 'Next message':
                  output.sioc_next_by_date.append(targetR)
               elif link.dfn.string == 'In reply to': 
                  output.sioc_reply_of.append(targetR)
               elif link.dfn.string == 'Next in thread': 
                  output.lists_next_in_thread.append(targetR)
               elif link.dfn.string == 'Reply': 
                  output.sioc_has_reply.append(targetR)
               elif link.dfn.string == 'Maybe reply': 
                  output.lists_maybe_reply.append(targetR)
               else:
                  print link.dfn.string + ' ' + target
              
               if predicate is not '':
                  output.rdf_type.append(ns.SIOC['Item'])
                  output.rdf_type.append(ns.DATAFAQS['Satisfactory'])
                  output.save()
      try:
         date = soup.find('span', {'id':'date'}).contents[1].replace(': ','')
         output.dcterms_date = date
         output.save()

         messageID = soup.find('span', {'id':'message-id'}).contents[1].replace(': &lt;','').replace('&gt;','').strip()
         output.dcterms_identifier = messageID
         output.save()
      except:
         pass
      
      # Get the body as prov:value: print  soup.find('pre', {'id': 'body'}).findAll(text=True)

      if ns.DATAFAQS['Satisfactory'] not in output.rdf_type:
         output.rdf_type.append(ns.DATAFAQS['Unsatisfactory'])

      output.save()

# Used when Twistd invokes this service b/c it is sitting in a deployed directory.
resource = W3CMailingListMessage()

# Used when this service is manually invoked from the command line (for testing).
if __name__ == '__main__':
   print resource.name + ' running on port ' + str(resource.dev_port) + '. Invoke it with:'
   print 'curl -H "Content-Type: text/turtle" -d @my.ttl http://localhost:' + str(resource.dev_port) + '/' + resource.name
   sadi.publishTwistedService(resource, port=resource.dev_port)
